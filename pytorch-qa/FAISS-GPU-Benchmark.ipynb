{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd93247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS, ElasticVectorSearch\n",
    "import elasticsearch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e70bdeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extracting the top-k value-indices from a 1-d ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how to display custom images in tensorboard (e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>python wheels: cp27mu not supported\\ni'm tryin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loading torch7 trained models (.t7) in pytorch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pytorch: how to use dataloaders for custom dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14588</th>\n",
       "      <td>how to disable neptune callback in transformer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14589</th>\n",
       "      <td>bgr to rgb for cub_200 images by image.split()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14590</th>\n",
       "      <td>neural networks extending learning domain\\ni h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14591</th>\n",
       "      <td>how do i multiply tensors like this?\\ni am wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14592</th>\n",
       "      <td>how do i multiply tensors like this?\\ni am wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14593 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      extracting the top-k value-indices from a 1-d ...\n",
       "1      how to display custom images in tensorboard (e...\n",
       "2      python wheels: cp27mu not supported\\ni'm tryin...\n",
       "3      loading torch7 trained models (.t7) in pytorch...\n",
       "4      pytorch: how to use dataloaders for custom dat...\n",
       "...                                                  ...\n",
       "14588  how to disable neptune callback in transformer...\n",
       "14589  bgr to rgb for cub_200 images by image.split()...\n",
       "14590  neural networks extending learning domain\\ni h...\n",
       "14591  how do i multiply tensors like this?\\ni am wor...\n",
       "14592  how do i multiply tensors like this?\\ni am wor...\n",
       "\n",
       "[14593 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### load data\n",
    "\n",
    "df = pd.read_csv(\"pt_question_answers.csv\")\n",
    "\n",
    "df[\"text\"] = df[\"pt_title\"] + \"\\n\" + df[\"pt_body\"] + \"\\n\" + df[\"pt_answer\"]\n",
    "\n",
    "df = df[[\"text\"]]\n",
    "\n",
    "CLEANR = re.compile('<.*?>') \n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleantext = re.sub(CLEANR, '', raw_html)\n",
    "    return cleantext\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: cleanhtml(x))\n",
    "\n",
    "df[\"text\"] = df[\"text\"].str.lower()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443769f9",
   "metadata": {},
   "source": [
    "## Custom Embeddings and FAISS index using dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c2b65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)\n",
    "model= nn.DataParallel(model)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "\n",
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:, 0]\n",
    "\n",
    "def get_embeddings(text_list):\n",
    "    encoded_input = tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    return cls_pooling(model_output)\n",
    "\n",
    "def get_context(question, truncate_length=512, k=5):\n",
    "\n",
    "    question_embedding = get_embeddings([question]).cpu().detach().numpy()\n",
    "\n",
    "    scores, samples = embeddings_dataset.get_nearest_examples(\n",
    "        \"embeddings\", question_embedding, k=k\n",
    "    )\n",
    "\n",
    "    samples_df = pd.DataFrame.from_dict(samples)\n",
    "    samples_df[\"scores\"] = scores\n",
    "    samples_df.sort_values(\"scores\", ascending=False, inplace=True)\n",
    "    samples_df[\"text\"] = samples_df[\"text\"].str[:truncate_length]\n",
    "\n",
    "    return samples_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c2e8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14593, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ca1100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5008f60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14593/14593 [04:54<00:00, 49.61it/s]\n"
     ]
    }
   ],
   "source": [
    "df[\"embeddings\"] = df.progress_apply(lambda x: get_embeddings(x[\"text\"]).detach().cpu().numpy()[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7469779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3553ff20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, \"embeddings\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf11703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14593, 768)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.embeddings.tolist()\n",
    "x = np.array(x)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02d626e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.random.rand(100, 512)\n",
    "# print(x.shape)\n",
    "x = x.reshape(x.shape[0], -1).astype('float32')\n",
    "d = x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "467cb615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14593, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ebf2e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0529a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "ngpus = faiss.get_num_gpus()\n",
    "\n",
    "ngpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e94d8d",
   "metadata": {},
   "source": [
    "### FAISS Indexing using GpuIndexFlatL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "987e7a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  202.40092277526855\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "res = faiss.StandardGpuResources()\n",
    "flat_config = faiss.GpuIndexFlatConfig()\n",
    "flat_config.useFloat16 = False\n",
    "flat_config.device = 0\n",
    "index = faiss.GpuIndexFlatL2(res, d, flat_config)\n",
    "\n",
    "index.add(x)\n",
    "\n",
    "print(\"time taken: \", (time.time() - start_time) * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872991d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db1cc7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fe5185a5dc4c1bb4a0379dd04558d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14593 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 56s, sys: 54 s, total: 19min 50s\n",
      "Wall time: 4min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = Dataset.from_pandas(df)\n",
    "\n",
    "embeddings_dataset = dataset.map(\n",
    "    lambda x: {\"embeddings\": get_embeddings(x[\"text\"]).detach().cpu().numpy()[0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cf61635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'embeddings'],\n",
       "    num_rows: 14593\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a4781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0db97520",
   "metadata": {},
   "source": [
    "### FAISS indexing using HF-add_faiss_index-IndexFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b1af300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918799c0635e4d40bc483588bb2d8910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  263.1490230560303\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "embeddings_dataset.add_faiss_index(column=\"embeddings\", device=0)\n",
    "\n",
    "print(\"time taken: \", (time.time() - start_time) * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d351f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c06b1f7",
   "metadata": {},
   "source": [
    "### FAISS indexing using HF-add_faiss_index - CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b6bb2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf460c415ce54cc0bc162df937d13943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  122.63202667236328\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")\n",
    "\n",
    "print(\"time taken: \", (time.time() - start_time) * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bca37cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.850589752197266"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# mem_bytes = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')  # e.g. 4015976448\n",
    "# mem_gib = mem_bytes/(1024.**3)  # e.g. 3.74\n",
    "\n",
    "# mem_gib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "872aca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import multiprocessing\n",
    "\n",
    "# multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13a16b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_dataset.save_faiss_index(\"embeddings\", \"embeddings.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0f70c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.7 ms, sys: 132 µs, total: 34.8 ms\n",
      "Wall time: 35.5 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>different method of running pytorch on gpu\\nse...</td>\n",
       "      <td>[-0.3892856538295746, -0.34232109785079956, -0...</td>\n",
       "      <td>24.639463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is there a way to allocate remaining gpu to yo...</td>\n",
       "      <td>[-0.23101496696472168, -0.38610121607780457, -...</td>\n",
       "      <td>23.941139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pytorch is not using gpu even it detects the g...</td>\n",
       "      <td>[-0.2389562726020813, -0.2919696867465973, -0....</td>\n",
       "      <td>21.565807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how to confirm that pytorch lightning is using...</td>\n",
       "      <td>[0.0017349837580695748, -0.5566844344139099, -...</td>\n",
       "      <td>21.380346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how do i check if pytorch is using the gpu?\\nh...</td>\n",
       "      <td>[-0.2592145800590515, -0.6313626170158386, -0....</td>\n",
       "      <td>17.069004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "4  different method of running pytorch on gpu\\nse...   \n",
       "3  is there a way to allocate remaining gpu to yo...   \n",
       "2  pytorch is not using gpu even it detects the g...   \n",
       "1  how to confirm that pytorch lightning is using...   \n",
       "0  how do i check if pytorch is using the gpu?\\nh...   \n",
       "\n",
       "                                          embeddings     scores  \n",
       "4  [-0.3892856538295746, -0.34232109785079956, -0...  24.639463  \n",
       "3  [-0.23101496696472168, -0.38610121607780457, -...  23.941139  \n",
       "2  [-0.2389562726020813, -0.2919696867465973, -0....  21.565807  \n",
       "1  [0.0017349837580695748, -0.5566844344139099, -...  21.380346  \n",
       "0  [-0.2592145800590515, -0.6313626170158386, -0....  17.069004  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_context('How do I check if PyTorch is using the GPU?', k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11057d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6e012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
