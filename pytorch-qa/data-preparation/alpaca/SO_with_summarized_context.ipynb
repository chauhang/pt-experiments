{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b96eb6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9fa8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean and process so\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    CLEANR = re.compile('<.*?>')\n",
    "    cleantext = re.sub(CLEANR, '', raw_html)\n",
    "    return cleantext\n",
    "    \n",
    "def clean_data(df):\n",
    "    df[\"pt_answer\"] = df[\"pt_answer\"].apply(lambda x: cleanhtml(x))\n",
    "\n",
    "    df[\"question\"] = df[\"pt_title\"].str.lower()\n",
    "    df[\"answer\"] = df[\"pt_answer\"].str.lower()\n",
    "\n",
    "    df = df[['pt_post_id','question', 'answer']]\n",
    "    return df\n",
    "    \n",
    "\n",
    "## get qa and link to post\n",
    "def get_url(df):\n",
    "    url = []\n",
    "    for index, row in df.iterrows():\n",
    "        url.append(f\"https://stackoverflow.com/questions/{row['pt_post_id']}/\")\n",
    "    \n",
    "    df['source'] = url\n",
    "\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('pt_question_answers_updated.csv')\n",
    "df = clean_data(df)\n",
    "df = get_url(df)\n",
    "df = df[['question','answer','source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cff14d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc0099c5",
   "metadata": {},
   "source": [
    "## create faiss index to fetch nearest docs and create context column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6ce36bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pages(df):\n",
    "    splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=2048)\n",
    "    print('chunking pages into smaller sub-pages')\n",
    "            \n",
    "    pages = []\n",
    "\n",
    "    for index, i in df.iterrows():\n",
    "        texts = \"QUESTION: \" + i['question'] + \"\\nANSWER: \" + i['answer']\n",
    "        meta = {'source':i['source']}\n",
    "        pages.extend(splitter.create_documents([texts], [meta]))\n",
    "    pickle.dump(pages, open('so_pages.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86e47b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2710, which is longer than the specified 2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunking pages into smaller sub-pages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 8837, which is longer than the specified 2048\n",
      "Created a chunk of size 2105, which is longer than the specified 2048\n",
      "Created a chunk of size 2466, which is longer than the specified 2048\n",
      "Created a chunk of size 2467, which is longer than the specified 2048\n"
     ]
    }
   ],
   "source": [
    "split_pages(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d06f1cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 pages done\n",
      "500 pages done\n",
      "1000 pages done\n",
      "1500 pages done\n",
      "2000 pages done\n",
      "2500 pages done\n",
      "3000 pages done\n",
      "3500 pages done\n",
      "4000 pages done\n",
      "4500 pages done\n",
      "5000 pages done\n",
      "5500 pages done\n",
      "6000 pages done\n",
      "6500 pages done\n",
      "7000 pages done\n",
      "7500 pages done\n",
      "8000 pages done\n",
      "8500 pages done\n",
      "9000 pages done\n",
      "9500 pages done\n",
      "10000 pages done\n",
      "10500 pages done\n",
      "11000 pages done\n",
      "11500 pages done\n",
      "12000 pages done\n",
      "12002 pages done\n"
     ]
    }
   ],
   "source": [
    "pages = pickle.load(open('so_pages.pkl', 'rb'))\n",
    "\n",
    "EMBED = \"hf\"\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "docsearch = FAISS.from_documents([pages.pop(0)], embeddings)\n",
    "i, step = 0, 50\n",
    "while i<len(pages):\n",
    "    if i%500==0:\n",
    "        print(i,'pages done')\n",
    "    texts = [d.page_content for d in pages[i:i+step]]\n",
    "    meta = [d.metadata for d in pages[i:i+step]]\n",
    "    docsearch.add_texts(texts, meta)\n",
    "    i += step\n",
    "print(len(pages),'pages done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ffeec",
   "metadata": {},
   "source": [
    "## query nearest 2 docs and create new column context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3d4832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10763/10763 [03:38<00:00, 49.33it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "docsearch = FAISS.load_local(\"so_faiss_index\", embeddings)\n",
    "context = []\n",
    "\n",
    "for index, i in tqdm(df.iterrows(),total=len(df)):\n",
    "    docs = docsearch.similarity_search_with_score(i['question'], k = 2)\n",
    "    ans = []\n",
    "    for doc in docs:\n",
    "        text = doc[0].page_content.split('ANSWER:')[-1].lstrip()\n",
    "        ans.append(\"Answer: \" + doc[0].page_content.split('ANSWER:')[-1])\n",
    "    for item in ans:\n",
    "        if i['answer'][:20] in item:\n",
    "            pass\n",
    "        else:\n",
    "            ans[0] = 'Answer: ' + i['answer']\n",
    "    context.append(', '.join(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1ac9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['context'] = context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8081f2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>source</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extracting the top-k value-indices from a 1-d ...</td>\n",
       "      <td>as of pull request #496 torch now includes a b...</td>\n",
       "      <td>https://stackoverflow.com/questions/34750268/</td>\n",
       "      <td>Answer: as of pull request #496 torch now incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how to display custom images in tensorboard (e...</td>\n",
       "      <td>it is quite easy to do if you have the image i...</td>\n",
       "      <td>https://stackoverflow.com/questions/38543850/</td>\n",
       "      <td>Answer: it is quite easy to do if you have the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>python wheels: cp27mu not supported</td>\n",
       "      <td>this is exactly that. \\nrecompile python under...</td>\n",
       "      <td>https://stackoverflow.com/questions/41767005/</td>\n",
       "      <td>Answer: this is exactly that. \\nrecompile pyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loading torch7 trained models (.t7) in pytorch</td>\n",
       "      <td>as of pytorch 1.0 torch.utils.serialization is...</td>\n",
       "      <td>https://stackoverflow.com/questions/41861354/</td>\n",
       "      <td>Answer: as of pytorch 1.0 torch.utils.serializ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pytorch: how to use dataloaders for custom dat...</td>\n",
       "      <td>yes, that is possible. just create the objects...</td>\n",
       "      <td>https://stackoverflow.com/questions/41924453/</td>\n",
       "      <td>Answer: yes, that is possible. just create the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10758</th>\n",
       "      <td>is it possible to perform quantization on dens...</td>\n",
       "      <td>here's how to do this on densenet169 from torc...</td>\n",
       "      <td>https://stackoverflow.com/questions/74612146/</td>\n",
       "      <td>Answer: here's how to do this on densenet169 f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10759</th>\n",
       "      <td>why when the batch size increased, the epoch t...</td>\n",
       "      <td>as you already noticed, there are many factors...</td>\n",
       "      <td>https://stackoverflow.com/questions/74637151/</td>\n",
       "      <td>Answer: as you already noticed, there are many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10760</th>\n",
       "      <td>why does stablediffusionpipeline return black ...</td>\n",
       "      <td>apparently it is indeed an apple silicon (m1/m...</td>\n",
       "      <td>https://stackoverflow.com/questions/74642594/</td>\n",
       "      <td>Answer: apparently it is indeed an apple silic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10761</th>\n",
       "      <td>locating tags in a string in php (with respect...</td>\n",
       "      <td>i think i've got something. how about this:\\nf...</td>\n",
       "      <td>https://stackoverflow.com/questions/74671399/</td>\n",
       "      <td>Answer: i think i've got something. how about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10762</th>\n",
       "      <td>bgr to rgb for cub_200 images by image.split()</td>\n",
       "      <td>i would strongly recommend you use skimage.io ...</td>\n",
       "      <td>https://stackoverflow.com/questions/74679922/</td>\n",
       "      <td>Answer: i would strongly recommend you use ski...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10763 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      extracting the top-k value-indices from a 1-d ...   \n",
       "1      how to display custom images in tensorboard (e...   \n",
       "2                    python wheels: cp27mu not supported   \n",
       "3         loading torch7 trained models (.t7) in pytorch   \n",
       "4      pytorch: how to use dataloaders for custom dat...   \n",
       "...                                                  ...   \n",
       "10758  is it possible to perform quantization on dens...   \n",
       "10759  why when the batch size increased, the epoch t...   \n",
       "10760  why does stablediffusionpipeline return black ...   \n",
       "10761  locating tags in a string in php (with respect...   \n",
       "10762     bgr to rgb for cub_200 images by image.split()   \n",
       "\n",
       "                                                  answer  \\\n",
       "0      as of pull request #496 torch now includes a b...   \n",
       "1      it is quite easy to do if you have the image i...   \n",
       "2      this is exactly that. \\nrecompile python under...   \n",
       "3      as of pytorch 1.0 torch.utils.serialization is...   \n",
       "4      yes, that is possible. just create the objects...   \n",
       "...                                                  ...   \n",
       "10758  here's how to do this on densenet169 from torc...   \n",
       "10759  as you already noticed, there are many factors...   \n",
       "10760  apparently it is indeed an apple silicon (m1/m...   \n",
       "10761  i think i've got something. how about this:\\nf...   \n",
       "10762  i would strongly recommend you use skimage.io ...   \n",
       "\n",
       "                                              source  \\\n",
       "0      https://stackoverflow.com/questions/34750268/   \n",
       "1      https://stackoverflow.com/questions/38543850/   \n",
       "2      https://stackoverflow.com/questions/41767005/   \n",
       "3      https://stackoverflow.com/questions/41861354/   \n",
       "4      https://stackoverflow.com/questions/41924453/   \n",
       "...                                              ...   \n",
       "10758  https://stackoverflow.com/questions/74612146/   \n",
       "10759  https://stackoverflow.com/questions/74637151/   \n",
       "10760  https://stackoverflow.com/questions/74642594/   \n",
       "10761  https://stackoverflow.com/questions/74671399/   \n",
       "10762  https://stackoverflow.com/questions/74679922/   \n",
       "\n",
       "                                                 context  \n",
       "0      Answer: as of pull request #496 torch now incl...  \n",
       "1      Answer: it is quite easy to do if you have the...  \n",
       "2      Answer: this is exactly that. \\nrecompile pyth...  \n",
       "3      Answer: as of pytorch 1.0 torch.utils.serializ...  \n",
       "4      Answer: yes, that is possible. just create the...  \n",
       "...                                                  ...  \n",
       "10758  Answer: here's how to do this on densenet169 f...  \n",
       "10759  Answer: as you already noticed, there are many...  \n",
       "10760  Answer: apparently it is indeed an apple silic...  \n",
       "10761  Answer: i think i've got something. how about ...  \n",
       "10762  Answer: i would strongly recommend you use ski...  \n",
       "\n",
       "[10763 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "13dcc5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('so_data_with_context.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ee614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab98c0f3",
   "metadata": {},
   "source": [
    "## using openai summarize this context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16e732de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                    | 136/10763 [01:04<1:26:54,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6b59b291b4d8a159e8c619acf0899f4f in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 201/10763 [01:30<46:14,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e5db53fd7c0b1cd8847304a043be7378 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▉                                      | 273/10763 [02:00<57:07,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 872199c0c291f2514e9426c9cfb6a0a0 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                   | 451/10763 [03:24<1:16:54,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5e9b7dd24a60cc2335b70d47ccbfd357 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▏                                  | 621/10763 [04:47<1:56:51,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7e23c5058b3c7a85f940df6f7188a141 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████                                  | 1159/10763 [08:57<37:19,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0d787eb49f9ce4a72de4d380fc3f747c in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███▉                                | 1176/10763 [09:06<1:03:23,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 195e81baa2f42a92a8f34fcaffdcad4f in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▏                             | 1856/10763 [14:42<2:56:50,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2c23000f08a08d9442df135e5c8d9d2d in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▍                              | 2108/10763 [16:38<47:11,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ce74677ef317bbf1ed991e5e56e96c4d in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████▌                            | 2253/10763 [17:45<1:03:43,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 78e1dc65c4e087b4d1d05a5d5b1b1ad9 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████                              | 2273/10763 [17:53<58:49,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d7de039dd4b4079bcecdd5a6aa18a7c8 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████▋                            | 2304/10763 [18:11<1:19:38,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5e86e09084f6e809f4c8ab41510882a0 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████▊                            | 2321/10763 [18:20<1:38:49,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7588031b5b74ee202a7748536f74c631 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▏                             | 2334/10763 [18:25<37:55,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: This model's maximum context length is 4097 tokens. However, your messages resulted in 4450 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████▉                            | 2366/10763 [18:40<1:24:19,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6e472e2c07c8bbf108800f5ac3287484 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▍                             | 2385/10763 [18:50<56:42,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1a499f7c8f51292d78c156df8befc11c in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████▋                           | 2603/10763 [20:49<1:04:44,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e8e6ced00e1c018b6f6cda46f4a3aac6 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████▎                            | 2654/10763 [21:11<43:59,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b6e51cf56d00f41c1815e3a6ae10022c in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████▎                          | 2771/10763 [22:09<1:01:40,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 45d79cdf9a0bd806ab7c685379db1adb in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████▍                          | 2830/10763 [22:39<1:22:52,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d51dea0bc40cc25ee49e60cb9381935a in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████                            | 2849/10763 [22:48<50:35,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 34ddd5e6e49a2e16d5078def3b01140e in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████                            | 2865/10763 [22:56<47:35,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ff1e64c70f37ac393fdae180cdc9a8e3 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████▊                          | 2937/10763 [23:28<1:28:02,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9d50385729c2655da2b77a74657c23f9 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████▍                           | 2942/10763 [23:30<56:23,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:43:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8da9855a06ec1b-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████▍                           | 2945/10763 [23:31<35:17,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:43:26 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8da97aac53c729-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████▍                           | 2946/10763 [23:31<42:14,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:43:26 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8da99d380c283b-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████▊                          | 2951/10763 [23:33<1:00:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:43:28 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8da9a7dbe7283b-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████▍                           | 2953/10763 [23:34<58:12,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:43:29 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8da99aba91c361-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████▌                           | 2981/10763 [23:48<53:42,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:43:43 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8da9f5cd6ec4a5-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████▊                           | 3048/10763 [24:22<48:18,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:17 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daa238e89c551-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████▊                           | 3051/10763 [24:23<38:36,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:18 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daae8691aec0f-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████▊                           | 3058/10763 [24:25<31:15,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:20 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daaaffdf6c4a0-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:20 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daad0db3fc4a5-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████▊                           | 3061/10763 [24:25<21:41,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:20 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daabf0b67092f-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████▊                           | 3065/10763 [24:25<20:09,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:20 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daaf668eac4a0-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daae788ea08df-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████▊                           | 3066/10763 [24:26<19:55,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daaf9deacec70-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daafc5e6fec98-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████▉                           | 3082/10763 [24:32<42:08,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:27 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daafede0bc38f-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:27 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab21c834ebe6-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████▉                           | 3086/10763 [24:34<46:09,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:29 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daaf80bf6092f-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████▉                           | 3092/10763 [24:34<24:59,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:30 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daaef5aedc361-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:30 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab2fba4ac4bb-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:30 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daae789d2c551-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:30 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab261eb4c38f-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:30 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab161dec30b1-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████▉                           | 3095/10763 [24:35<25:02,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:30 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daad15c3bc729-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:30 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daafebcfa683a-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████▉                           | 3099/10763 [24:35<17:08,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:30 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab33be51c4bb-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:31 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab354cf230b1-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:31 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab377933c729-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:31 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daafbb99b08df-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████▉                           | 3103/10763 [24:36<17:51,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:31 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daae8ded8c4de-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:31 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daaf1cd78c678-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████▉                           | 3109/10763 [24:37<11:35, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:32 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab3d9c51ec98-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:32 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab3e7867c4de-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:32 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab40c8a9c3aa-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: This model's maximum context length is 4097 tokens. However, your messages resulted in 4766 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████▉                           | 3111/10763 [24:37<22:06,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:33 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab34bb39c38f-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:33 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab076c0430ac-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████▉                           | 3113/10763 [24:38<20:16,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:33 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab4178cdec98-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:33 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daaf4de51ec40-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████▉                           | 3115/10763 [24:38<18:37,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:33 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daafb1dcec4a0-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████                           | 3117/10763 [24:38<22:55,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:33 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab480862ec98-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab1bd885ebfa-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab3c8b00ec0f-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab3c19bd283b-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████                           | 3121/10763 [24:39<18:08,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daafd4b43ec70-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab3abb5908df-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████                           | 3122/10763 [24:39<18:46,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab339fdac361-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████                           | 3123/10763 [24:39<21:47,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab340e15c551-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab21e97eec1b-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab0b7cd0c77a-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab43c801ebe6-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████                           | 3128/10763 [24:40<14:26,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab178e9908a1-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab4e6b20ec70-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████                           | 3133/10763 [24:40<09:29, 13.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab4ccc9dec0f-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab476e5930ac-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab342eb530ba-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daaf6fb77c4a5-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab48c880ec40-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████                           | 3139/10763 [24:40<08:13, 15.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab5049cec361-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab2b49552768-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab52392aebe6-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8daaf25823283b-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab552e06ec0f-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab57badc283b-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab496b59c4a0-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████                           | 3143/10763 [24:41<09:14, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:36 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab39fa5230b1-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:36 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab54aa25ec70-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████                           | 3147/10763 [24:41<15:08,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:36 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab2b8b8dec64-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:36 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab578f40ebe6-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n",
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:44:37 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dab58cc6fc4a0-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████▋                          | 3327/10763 [26:16<49:09,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b26451777655c4886cbc01fc6d58f182 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████▊                          | 3340/10763 [26:20<32:01,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 56e799d5ca1edf600a76332c01a1d465 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████▍                         | 3521/10763 [27:45<43:33,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a768b1acd1fc1690e6f871cecbd525d4 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████▌                         | 3568/10763 [28:07<54:32,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c91c23ae1ceceff8bc7122648e8695fe in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████▋                         | 3603/10763 [28:23<47:21,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 07f46befc7b91f7f5f95d0591a29250f in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████▍                       | 3717/10763 [29:14<1:17:50,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3a5fc5e6a1523529ca13698571913abd in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████▌                       | 3753/10763 [29:32<1:04:43,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 512f16841352446c03ed75a5441fed4c in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████▌                        | 3830/10763 [30:11<54:36,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6f1f09ba8e084c10123c1e51b7acbedc in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████▊                       | 3834/10763 [30:14<1:04:02,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4b6cd91de975c9d6ab1e62c27abf2ab9 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████▉                        | 3961/10763 [31:14<50:17,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9dc455232fe1518e4b21cc3eca0b0b07 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████▏                       | 4015/10763 [31:42<33:02,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4496b5c14a79dd58aed9748ccf7c8468 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████                      | 4193/10763 [33:10<1:10:04,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a7e615f7adc22f88ab38dc94d1b9e2f4 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████▏                     | 4257/10763 [33:43<1:29:48,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d862db659be6cab8c45e52319b52076b in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████▍                     | 4300/10763 [34:06<1:08:54,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1a1b55953d1ce20c70a0bd8c3ff23451 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▎                      | 4329/10763 [34:20<35:37,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 02bb2e3836a8cf274275e207a4a256d7 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▎                      | 4334/10763 [34:22<30:51,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: This model's maximum context length is 4097 tokens. However, your messages resulted in 4257 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▎                      | 4338/10763 [34:23<26:05,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a0d7a41f69569a03f72417f23fe47ee3 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████▉                      | 4507/10763 [35:46<20:15,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4b94efa5b311fee262ae8cb658501298 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████▎                    | 4592/10763 [36:23<1:14:29,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:56:19 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8db4a97b44c678-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████▍                     | 4645/10763 [36:45<35:51,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: This model's maximum context length is 4097 tokens. However, your messages resulted in 4684 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████▍                     | 4654/10763 [36:49<41:40,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d98e16555f4a313a4e26040886e2520b in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████▌                    | 4661/10763 [36:54<1:40:34,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d6205d550b88b2e0b138ba4c179cddb0 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████▊                    | 4738/10763 [37:37<1:22:17,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e22588c303a73761732af674b099b3ce in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████▉                    | 4774/10763 [37:54<1:16:03,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 81e7fcd38dd8daa5268bcdec1edee654 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████▌                    | 4978/10763 [39:33<41:33,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 17:59:28 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8db947b8fc30ac-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████▏                  | 5451/10763 [43:16<48:27,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8782225b940d99289cec66cf13a7be6b in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████▋                  | 5579/10763 [44:14<46:20,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2d3e064d8d9ddb72dd2fcb010f8836ff in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|████████████████████▏                 | 5729/10763 [45:26<43:19,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1daf981a46a89b58d7e4d621ef9d43c3 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████▍                 | 5790/10763 [45:49<24:08,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4e16ac48d6ee6c22955935ee2b97d9e1 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████▉                 | 5937/10763 [46:54<43:42,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c52e82a620d5c8b921e4c6b908613ca0 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████▋                | 6152/10763 [48:37<28:02,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8f90614b9e8b93151c13c252a890e66c in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████▊                | 6192/10763 [49:00<38:22,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 14ba00b7276069d88677e933bbf2c78d in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████▎               | 6325/10763 [49:55<31:19,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d090b3c7378d03b38785b628cf7279af in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████▌               | 6382/10763 [50:20<14:11,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2f5888912a0ffe6bbe2726ae2ccbdc25 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████▉               | 6494/10763 [51:16<38:41,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0653159acc854411749172c3ee7197af in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████               | 6539/10763 [51:37<24:03,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3e772811eb0c0a02bff8a2da5933faf6 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████▎             | 6870/10763 [54:03<39:46,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f35faa9553e68c81caa351d66b2e7ca9 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████▋             | 6989/10763 [55:00<26:31,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b20ad52462ae751cfa7d8fe024812aa0 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████▊             | 7041/10763 [55:27<23:51,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7c2ef582116eb6a0bccf18d28286acb9 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████             | 7099/10763 [55:56<22:05,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 91a1838c104bdf36666e6ae318f2d613 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████▍            | 7219/10763 [57:01<16:43,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 867014d49a20d57b692e8e0346ec5681 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████▋            | 7287/10763 [57:35<23:20,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7ea4d2d3c3c861e156861b59179ce35f in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████▉            | 7329/10763 [57:55<25:05,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 57806d01ea283efbb2ab25ecfcdf8f97 in your message.)\n",
      "generated an exception: This model's maximum context length is 4097 tokens. However, your messages resulted in 7091 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████▉            | 7333/10763 [57:56<18:18,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID db11e2563633207e13f4cded56b37dbe in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████▉            | 7335/10763 [57:56<18:17,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID aab15348f1aa4631896a766354b7cd9a in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████▌          | 7650/10763 [1:00:18<19:28,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4a5d08a4912de1c47671b91574899c07 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████▌          | 7653/10763 [1:00:20<25:29,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cc14b5a8c4c9e14aab697fe564597dbc in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████▌         | 7952/10763 [1:02:28<10:44,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f6252ccc86f763fde56e2c184ba5eaac in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████▉         | 8071/10763 [1:03:18<12:25,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6846b082d20dde9fa7be3abb5d71d550 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████         | 8092/10763 [1:03:28<29:18,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ac5fdd309588a8ab6fd2feaaa449997c in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████▏       | 8421/10763 [1:05:49<17:31,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 36ccdcf1fdc2a6ccc6b9876ae87e9a1c in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████▏       | 8426/10763 [1:05:51<13:50,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID afabf09c04b84dfa9a9651bc4beadb62 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████▍       | 8512/10763 [1:06:29<14:43,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e35a4c862516b9b0ea632dea04e5bea3 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████▋       | 8563/10763 [1:06:52<11:58,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b14fae5ecee13c8dd6ee1fd18e616c24 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████▏      | 8708/10763 [1:07:45<10:02,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: This model's maximum context length is 4097 tokens. However, your messages resulted in 5229 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████▍      | 8793/10763 [1:08:24<19:20,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d26ec24a440f529e9b435b2fe189e464 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████▍      | 8817/10763 [1:08:34<14:09,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a54f336c2ec827e589ecafb5707bbb89 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████▉      | 8935/10763 [1:09:23<10:58,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 22650a6435ff88d4cc6fe88f4d4a0c10 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████      | 8984/10763 [1:09:41<17:40,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 25d68000fc6ead53e2a87969f4b8bcaa in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████      | 8996/10763 [1:09:46<15:31,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 59067e0b22b0b4005da57fc46d07b6dc in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████▊     | 9225/10763 [1:11:30<12:45,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 501671ad74b8f139484f783977c35ab5 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████     | 9270/10763 [1:11:50<07:48,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e3027df8f513ebe37e904c5694c98bf3 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████▎    | 9357/10763 [1:12:26<12:28,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e5216734e664cfa8488f0b0d2e868828 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████    | 9579/10763 [1:14:03<08:58,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c5aea1ba745b7777917eb6a9d3afe4d8 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████▎   | 9648/10763 [1:14:31<05:56,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: This model's maximum context length is 4097 tokens. However, your messages resulted in 4491 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████▊   | 9799/10763 [1:15:29<03:05,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID acf7901726ec2a181ec02dacf0e7e050 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████▏  | 9939/10763 [1:16:31<07:37,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1c46595c353b17984e3209a0d04e1137 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████▌  | 10022/10763 [1:17:09<03:27,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 457c25b1eb5c30865bcd33e7017df379 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████▊  | 10104/10763 [1:17:44<03:45,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5f7a2236030f78f47e28d0103ef4bd39 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████▏ | 10194/10763 [1:18:24<04:45,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b412563e37414e4eb3eaa1dd6d64cb09 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████▍ | 10289/10763 [1:19:03<03:36,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 85bcf5c4d5128200d729f49bfd872219 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████▌ | 10311/10763 [1:19:14<04:33,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2705b0dbe8f228d2637530c374ce5ccd in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████▋ | 10351/10763 [1:19:30<03:05,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 34d8703dc4b513cdbca5eb71726c8abe in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████▍| 10587/10763 [1:21:11<00:44,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d2f2e68a39fa6a34ad871674827dd759 in your message.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10763/10763 [1:26:25<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated an exception: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Wed, 17 May 2023 18:46:20 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7c8dfe082cbbc729-SEA', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import concurrent.futures\n",
    "import requests\n",
    "import openai\n",
    "\n",
    "api_key = ''\n",
    "\n",
    "def get_qa_openai(context, index):\n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\", api_key = api_key,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": context}\n",
    "                  ]\n",
    "                )\n",
    "\n",
    "        qa = completion.choices[0].message.content\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f'Request failed with error: {str(e)}.')\n",
    "        print(f'Waiting for 3 minutes before trying again...')\n",
    "        time.sleep(180)\n",
    "    \n",
    "    return (qa, index)\n",
    "\n",
    "questions_ans = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    \n",
    "    futures = []\n",
    "    for index,i in df.iterrows():\n",
    "\n",
    "        context = f\"Reduce the context size as much as you can in the following context but preserve the code and important details that answers the question: \\\n",
    "                    question: {i['question']}, context:{i['context']}\"\n",
    "        \n",
    "        futures.append(executor.submit(get_qa_openai, context, index))\n",
    "\n",
    "    for future, (_, row) in tqdm(zip(concurrent.futures.as_completed(futures), df.iterrows()), total=len(df)):\n",
    "        try:\n",
    "            qa, ind = future.result()\n",
    "            questions_ans.append((ind,qa))\n",
    "        except Exception as exc:\n",
    "            print(f'generated an exception: {exc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "079ef6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, qa in questions_ans:\n",
    "    df.at[index, 'context_summary'] = qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da162c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>source</th>\n",
       "      <th>context</th>\n",
       "      <th>context_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extracting the top-k value-indices from a 1-d ...</td>\n",
       "      <td>as of pull request #496 torch now includes a b...</td>\n",
       "      <td>https://stackoverflow.com/questions/34750268/</td>\n",
       "      <td>Answer: as of pull request #496 torch now incl...</td>\n",
       "      <td>To extract the top-k value-indices from a 1-d ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how to display custom images in tensorboard (e...</td>\n",
       "      <td>it is quite easy to do if you have the image i...</td>\n",
       "      <td>https://stackoverflow.com/questions/38543850/</td>\n",
       "      <td>Answer: it is quite easy to do if you have the...</td>\n",
       "      <td>Answer: use the gen_plot() function to create ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>python wheels: cp27mu not supported</td>\n",
       "      <td>this is exactly that. \\nrecompile python under...</td>\n",
       "      <td>https://stackoverflow.com/questions/41767005/</td>\n",
       "      <td>Answer: this is exactly that. \\nrecompile pyth...</td>\n",
       "      <td>Answer: To fix the issue of the \"cp27mu not su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loading torch7 trained models (.t7) in pytorch</td>\n",
       "      <td>as of pytorch 1.0 torch.utils.serialization is...</td>\n",
       "      <td>https://stackoverflow.com/questions/41861354/</td>\n",
       "      <td>Answer: as of pytorch 1.0 torch.utils.serializ...</td>\n",
       "      <td>Question: loading torch7 trained models (.t7) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pytorch: how to use dataloaders for custom dat...</td>\n",
       "      <td>yes, that is possible. just create the objects...</td>\n",
       "      <td>https://stackoverflow.com/questions/41924453/</td>\n",
       "      <td>Answer: yes, that is possible. just create the...</td>\n",
       "      <td>Question: How to use dataloaders for custom da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10758</th>\n",
       "      <td>is it possible to perform quantization on dens...</td>\n",
       "      <td>here's how to do this on densenet169 from torc...</td>\n",
       "      <td>https://stackoverflow.com/questions/74612146/</td>\n",
       "      <td>Answer: here's how to do this on densenet169 f...</td>\n",
       "      <td>Answer: To perform quantization on densenet169...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10759</th>\n",
       "      <td>why when the batch size increased, the epoch t...</td>\n",
       "      <td>as you already noticed, there are many factors...</td>\n",
       "      <td>https://stackoverflow.com/questions/74637151/</td>\n",
       "      <td>Answer: as you already noticed, there are many...</td>\n",
       "      <td>Q: Why does increasing the batch size increase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10760</th>\n",
       "      <td>why does stablediffusionpipeline return black ...</td>\n",
       "      <td>apparently it is indeed an apple silicon (m1/m...</td>\n",
       "      <td>https://stackoverflow.com/questions/74642594/</td>\n",
       "      <td>Answer: apparently it is indeed an apple silic...</td>\n",
       "      <td>Answer: The stablediffusionpipeline returns bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10761</th>\n",
       "      <td>locating tags in a string in php (with respect...</td>\n",
       "      <td>i think i've got something. how about this:\\nf...</td>\n",
       "      <td>https://stackoverflow.com/questions/74671399/</td>\n",
       "      <td>Answer: i think i've got something. how about ...</td>\n",
       "      <td>Answer: You can use the function label_italics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10762</th>\n",
       "      <td>bgr to rgb for cub_200 images by image.split()</td>\n",
       "      <td>i would strongly recommend you use skimage.io ...</td>\n",
       "      <td>https://stackoverflow.com/questions/74679922/</td>\n",
       "      <td>Answer: i would strongly recommend you use ski...</td>\n",
       "      <td>Answer: To convert bgr to rgb for cub_200 imag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10763 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      extracting the top-k value-indices from a 1-d ...   \n",
       "1      how to display custom images in tensorboard (e...   \n",
       "2                    python wheels: cp27mu not supported   \n",
       "3         loading torch7 trained models (.t7) in pytorch   \n",
       "4      pytorch: how to use dataloaders for custom dat...   \n",
       "...                                                  ...   \n",
       "10758  is it possible to perform quantization on dens...   \n",
       "10759  why when the batch size increased, the epoch t...   \n",
       "10760  why does stablediffusionpipeline return black ...   \n",
       "10761  locating tags in a string in php (with respect...   \n",
       "10762     bgr to rgb for cub_200 images by image.split()   \n",
       "\n",
       "                                                  answer  \\\n",
       "0      as of pull request #496 torch now includes a b...   \n",
       "1      it is quite easy to do if you have the image i...   \n",
       "2      this is exactly that. \\nrecompile python under...   \n",
       "3      as of pytorch 1.0 torch.utils.serialization is...   \n",
       "4      yes, that is possible. just create the objects...   \n",
       "...                                                  ...   \n",
       "10758  here's how to do this on densenet169 from torc...   \n",
       "10759  as you already noticed, there are many factors...   \n",
       "10760  apparently it is indeed an apple silicon (m1/m...   \n",
       "10761  i think i've got something. how about this:\\nf...   \n",
       "10762  i would strongly recommend you use skimage.io ...   \n",
       "\n",
       "                                              source  \\\n",
       "0      https://stackoverflow.com/questions/34750268/   \n",
       "1      https://stackoverflow.com/questions/38543850/   \n",
       "2      https://stackoverflow.com/questions/41767005/   \n",
       "3      https://stackoverflow.com/questions/41861354/   \n",
       "4      https://stackoverflow.com/questions/41924453/   \n",
       "...                                              ...   \n",
       "10758  https://stackoverflow.com/questions/74612146/   \n",
       "10759  https://stackoverflow.com/questions/74637151/   \n",
       "10760  https://stackoverflow.com/questions/74642594/   \n",
       "10761  https://stackoverflow.com/questions/74671399/   \n",
       "10762  https://stackoverflow.com/questions/74679922/   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Answer: as of pull request #496 torch now incl...   \n",
       "1      Answer: it is quite easy to do if you have the...   \n",
       "2      Answer: this is exactly that. \\nrecompile pyth...   \n",
       "3      Answer: as of pytorch 1.0 torch.utils.serializ...   \n",
       "4      Answer: yes, that is possible. just create the...   \n",
       "...                                                  ...   \n",
       "10758  Answer: here's how to do this on densenet169 f...   \n",
       "10759  Answer: as you already noticed, there are many...   \n",
       "10760  Answer: apparently it is indeed an apple silic...   \n",
       "10761  Answer: i think i've got something. how about ...   \n",
       "10762  Answer: i would strongly recommend you use ski...   \n",
       "\n",
       "                                         context_summary  \n",
       "0      To extract the top-k value-indices from a 1-d ...  \n",
       "1      Answer: use the gen_plot() function to create ...  \n",
       "2      Answer: To fix the issue of the \"cp27mu not su...  \n",
       "3      Question: loading torch7 trained models (.t7) ...  \n",
       "4      Question: How to use dataloaders for custom da...  \n",
       "...                                                  ...  \n",
       "10758  Answer: To perform quantization on densenet169...  \n",
       "10759  Q: Why does increasing the batch size increase...  \n",
       "10760  Answer: The stablediffusionpipeline returns bl...  \n",
       "10761  Answer: You can use the function label_italics...  \n",
       "10762  Answer: To convert bgr to rgb for cub_200 imag...  \n",
       "\n",
       "[10763 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ffb8ef",
   "metadata": {},
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "841b924a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question             0\n",
       "answer               0\n",
       "source               0\n",
       "context              0\n",
       "context_summary    171\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a14c113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop na\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff9ad10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4452/1588506768.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['len'] = df['context_summary'].str.len()\n"
     ]
    }
   ],
   "source": [
    "## checking context len\n",
    "\n",
    "df['len'] = df['context_summary'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ddf6480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjdElEQVR4nO3de3RU1d3/8c8JlyEIiQshN4mKeK0itl4oq8pCygLCHZGqtY+gLvwVgn0wojx5lki99Em1CngJCSAk3rhmcilqQZtCqAKiVKT8rDxA6Q8UcpGaDAQTIpnfH4Qhk0xCMpnMmcx+v9Y63XP22Wfvb0dcfJw5ybbcbrdbAAAABouwuwAAAAC7EYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIzX2e4C2lttba2OHDminj17yrIsu8sBAAAt4Ha7dfz4cSUkJCgiov0/vwn7QHTkyBElJibaXQYAAPDD4cOH1bdv33ZfJ+wDUc+ePSWdeUOjoqJsrgYAALSEy+VSYmKi5+/x9hb2gejs12RRUVEEIgAAOphgPe7CQ9UAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4tgaitLQ03XLLLerZs6diYmI0ceJE7d2712vM0KFDZVmW1/HrX//apooBAEA4sjUQFRUVKTk5Wdu3b9eHH36ompoajRgxQpWVlV7jpk+frqNHj3qOF154waaKAQBAOOps5+IbNmzwOs/OzlZMTIx27typIUOGePq7d++uuLi4Fs1ZXV2t6upqz7nL5QpMsQAAIGyF1DNEFRUVkqRevXp59b/zzjvq3bu3rr/+eqWmpurkyZNNzpGWlqbo6GjPkZiY2K41AwCAjs9yu91uu4uQpNraWo0fP17l5eX66KOPPP1Lly7VpZdeqoSEBO3evVtz587VrbfeqtzcXJ/z+PqEKDExURUVFYqKimr3/x8AAKDtXC6XoqOjg/b3t61fmdWXnJysPXv2eIUhSXr44Yc9rwcMGKD4+Hj9/Oc/14EDB9S/f/9G8zgcDjkcjnavFwAAhI+Q+Mps1qxZevfdd7Vp0yb17du32bGDBg2SJO3fvz8YpQEAAAPY+gmR2+3WI488ory8PG3evFn9+vU77z27du2SJMXHx7dzdQAAwBS2BqLk5GStXLlSBQUF6tmzp4qLiyVJ0dHRioyM1IEDB7Ry5UqNHj1aF110kXbv3q1HH31UQ4YM0Q033GBn6QAAIIzY+lC1ZVk++7OysjRt2jQdPnxYv/rVr7Rnzx5VVlYqMTFRkyZN0pNPPtniB6yC/VAWAABoO6Meqj5fFktMTFRRUVGQqgEAAKYKiYeqAQAA7EQgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyCC8RasHGl3CQAAmxGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQhhKfOtpjdsfeUd/zZzfXYNm8ACQLgiEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA49kaiNLS0nTLLbeoZ8+eiomJ0cSJE7V3716vMVVVVUpOTtZFF12kHj16aPLkySopKbGpYgAAEI5sDURFRUVKTk7W9u3b9eGHH6qmpkYjRoxQZWWlZ8yjjz6q9evXa926dSoqKtKRI0d055132lg1AAAIN53tXHzDhg1e59nZ2YqJidHOnTs1ZMgQVVRUaPny5Vq5cqWGDRsmScrKytK1116r7du366c//akdZQMAgDATUs8QVVRUSJJ69eolSdq5c6dqamo0fPhwz5hrrrlGl1xyibZt2+ZzjurqarlcLq8DAACgOSETiGprazV79mz97Gc/0/XXXy9JKi4uVteuXXXhhRd6jY2NjVVxcbHPedLS0hQdHe05EhMT27t0AADQwYVMIEpOTtaePXu0evXqNs2TmpqqiooKz3H48OEAVQgAAMKVrc8QnTVr1iy9++672rJli/r27evpj4uL06lTp1ReXu71KVFJSYni4uJ8zuVwOORwONq7ZAAAEEZs/YTI7XZr1qxZysvL01/+8hf169fP6/pNN92kLl26qLCw0NO3d+9eHTp0SIMHDw52uQAAIEzZ+glRcnKyVq5cqYKCAvXs2dPzXFB0dLQiIyMVHR2thx56SCkpKerVq5eioqL0yCOPaPDgwfyEGQAACBhbA1FGRoYkaejQoV79WVlZmjZtmiRp4cKFioiI0OTJk1VdXa2RI0dq8eLFQa4UAACEM1sDkdvtPu+Ybt26KT09Xenp6UGoCAAAmChkfsoMAADALgQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxAh5L2RPaJV4zPfGtlOlQAAwhWBCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCERolY3LR9tdQiOvv+nf7vaLVja+7w+rRuqFVS2fb966UX6tHUyj8+fZXQIAhDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgQdOuyvHeIX53l3271y98cEYhympW2umW1/XcAdr0fX+A9R1LB3W2eEwDQMgQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIIKt1tTb6HVltn+bvJ619K223R8IT+S0fZNXf43On2Pb2gDQ0RGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxbA1EW7Zs0bhx45SQkCDLspSfn+91fdq0abIsy+sYNcq+3wQMAADCk62BqLKyUgMHDlR6enqTY0aNGqWjR496jlWrVgWxQgAAYILOdi6elJSkpKSkZsc4HA7FxcUFqSIAAGCikH+GaPPmzYqJidHVV1+tGTNm6NixY82Or66ulsvl8joAAACaE9KBaNSoUXrzzTdVWFio559/XkVFRUpKStLp06ebvCctLU3R0dGeIzExMYgV22dX5ji7Swh5r70zMuhr/qez+Wfefpk/Sr8o8B6T9MfxrV5ndH5Kq+8BAJzjVyAaNmyYysvLG/W7XC4NGzasrTV53HPPPRo/frwGDBigiRMn6t1339Wnn36qzZs3N3lPamqqKioqPMfhw4cDVg8AAAhPfgWizZs369SpU436q6qq9Ne//rXNRTXl8ssvV+/evbV///4mxzgcDkVFRXkdAAAAzWnVQ9W7d+/2vP7yyy9VXFzsOT99+rQ2bNigiy++OHDVNfD111/r2LFjio+Pb7c1AACAeVoViG688UbP7wPy9dVYZGSkXn311RbPd+LECa9Pew4ePKhdu3apV69e6tWrl55++mlNnjxZcXFxOnDggJ544gldccUVGjky+M+CAACA8NWqQHTw4EG53W5dfvnl2rFjh/r06eO51rVrV8XExKhTp04tnu+zzz7THXfc4TlPSTnzYOjUqVOVkZGh3bt364033lB5ebkSEhI0YsQIPfvss3I4HK0pGwAAoFmtCkSXXnqpJKm2tjYgiw8dOlRut7vJ6xs3bgzIOgAAAM3x+xcz7tu3T5s2bVJpaWmjgPTUU0+1uTAAAIBg8SsQLVu2TDNmzFDv3r0VFxcny7I81yzLIhABAIAOxa9A9Nxzz+l3v/ud5s6dG+h6AAAAgs6v30P03XffacqUKYGuBQAAwBZ+BaIpU6bogw8+CHQtAAAAtvDrK7MrrrhC8+bN0/bt2zVgwAB16dLF6/pvfvObgBQHAAAQDH4FoqVLl6pHjx4qKipSUVGR1zXLsghEBvjT8tFySxr90Pte/etXJGncg39SwYokTXjwT62ed2X2SP1ymu9ft5D9xghNm9q2TyZfrdvg9eWVZ9qFK8/9ks8XV/n+hZ//s3qkai2fl2yRVPBr/WlCpt1lAEBY8SsQHTx4MNB1AAAA2MavZ4gAAADCiV+fED344IPNXl+xYoVfxQAAANjBr0D03XffeZ3X1NRoz549Ki8v97npKwAAQCjzKxDl5eU16qutrdWMGTPUv3//NhcFAAAQTAF7higiIkIpKSlauHBhoKYEAAAIioA+VH3gwAH98MMPgZwSAACg3fn1lVlKSorXudvt1tGjR/Xee+9p6tSpASkMAAAgWPwKRJ9//rnXeUREhPr06aOXXnrpvD+BBgAAEGr8CkSbNm0KdB0AAAC28SsQnVVWVqa9e/dKkq6++mr16dMnIEUBAAAEk18PVVdWVurBBx9UfHy8hgwZoiFDhighIUEPPfSQTp48GegaAQAA2pVfgSglJUVFRUVav369ysvLVV5eroKCAhUVFemxxx4LdI0AAADtyq9A5HQ6tXz5ciUlJSkqKkpRUVEaPXq0li1bppycnEDXiFb4W+a4Vo3/67Ix7VTJGXkrkpq8tjZrlM/+d7J97zofTM+vHqnfr25cxzNrzvTNX+u79vN5OM/3fZMLmp4vqeB+JRVM82u95ozOey7gcwJAR+VXIDp58qRiY2Mb9cfExPCVGQAA6HD8CkSDBw/W/PnzVVVV5en7/vvv9fTTT2vw4MEBKw4AACAY/Pops0WLFmnUqFHq27evBg4cKEn64osv5HA49MEHHwS0QAAAgPbmVyAaMGCA9u3bp3feeUdfffWVJOnee+/Vfffdp8jIyIAWCAAA0N78CkRpaWmKjY3V9OnTvfpXrFihsrIyzZ07NyDFAQAABINfzxAtWbJE11xzTaP+6667TpmZmW0uCgAAIJj8CkTFxcWKj49v1N+nTx8dPXq0zUUBAAAEk1+BKDExUR9//HGj/o8//lgJCQltLgoAACCY/HqGaPr06Zo9e7Zqamo0bNgwSVJhYaGeeOIJflM1AADocPwKRI8//riOHTummTNn6tSpU5Kkbt26ae7cuUpNTQ1ogQAAAO3Nr0BkWZaef/55zZs3T//4xz8UGRmpK6+8Ug6HI9D1AQAAtDu/AtFZPXr00C233BKoWgAAAGzh10PVCIzDr02zu4R28cdmNnQNtsVvn9mM9bW37d8w1h9JBb+s9/qhxtfzf9PkvaPz/7tdagKAcEQgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AlEY+3TJOM/r7UvHSpK21rVtsWH56BaNy6/b9T43a5QkyVnX+rIq297d6F9a1fL1n17b9lofyGv6vQgVY/L+0PS13JeDWEnLjM1ZaXcJADowAhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMJ6tgWjLli0aN26cEhISZFmW8vPzva673W499dRTio+PV2RkpIYPH659+/bZUywAAAhbtgaiyspKDRw4UOnp6T6vv/DCC3rllVeUmZmpTz75RBdccIFGjhypqqqqIFcKAADCWWc7F09KSlJSUpLPa263W4sWLdKTTz6pCRMmSJLefPNNxcbGKj8/X/fcc4/P+6qrq1VdXe05d7lcgS8cAACElZB9hujgwYMqLi7W8OHDPX3R0dEaNGiQtm3b1uR9aWlpio6O9hyJiYkBras086VW33Mk/TGv869f+3WgyjmvHfU2eG2LD5rY0PX9Fm70elZO3Qav65rZ6PWst5rY8HXFGyNatWao+o98/zd4TSqYqaT8Rxr1j85/vC0lndeY3IUNzl+pa1+ra31/2ns+Y53L21ZYa9Zaty5oawHoOEI2EBUXF0uSYmNjvfpjY2M913xJTU1VRUWF5zh8+HC71gkAADo+W78yaw8Oh0MOh8PuMgAAQAcSsp8QxcXFSZJKSkq8+ktKSjzXAAAAAiFkA1G/fv0UFxenwsJCT5/L5dInn3yiwYMH21gZAAAIN7Z+ZXbixAnt37/fc37w4EHt2rVLvXr10iWXXKLZs2frueee05VXXql+/fpp3rx5SkhI0MSJE+0rGgAAhB1bA9Fnn32mO+64w3OekpIiSZo6daqys7P1xBNPqLKyUg8//LDKy8t12223acOGDerWrZtdJQMAgDBkayAaOnSo3G53k9cty9IzzzyjZ555JohVAQAA04TsM0QAAADBQiACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AlEI+uerE1s8dnfG+EZ9OzP93+F+0+tj/L53/Yokv+8Nd8m5/u9sX19SwcPnHTM6f26r5hyd9z917e/r2ue9ro/JfanB+aK69uVWrQMAoYxABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQ+lGVmtHhsSUZawNb9f69M9Lw+8OoEz+u96RP0VfoEr7F7Fp/b1PULHxu8BsqfXx/dbnMHS/rbI4O+5mPOtm3mmlRwZ8vH5s9u1Dc6/7/atH5rjMl9ta59zfd1Z6bGOJf46H+9Ud9YZ1Zdm92g/8021Tg2Z22b7gcQ/ghEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxnZCAqy8j23Z+51Gd/aeYrde3C9iopKLYtHdvktaJlY/ye970VSXp3RZLf97eXDBt2uW+rpD+Oare5R+fNr2ufbvW9Y3IX+HFPhu9+57JWz9WUsTnv+OhbpbE5q/2ab1xOfhsrkibkfOCzf2LOX9o8N4D2Y2QgAgAAqI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYjqlGUua3C+2JY6Dr4yMSDzfLZkXEDmCZTcrPbbtBShZUzuYo3Jteffn9Yal+Ns9T3jc95rh0qaNtn5SYvGTXH+vZ0rAcIbgQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGC+kA9Fvf/tbWZbldVxzzTV2lwUAAMJMZ7sLOJ/rrrtOf/7znz3nnTuHfMkAAKCDCfl00blzZ8XFxdldBgAACGMh/ZWZJO3bt08JCQm6/PLLdd999+nQoUPNjq+urpbL5fI6AAAAmhPSgWjQoEHKzs7Whg0blJGRoYMHD+r222/X8ePHm7wnLS1N0dHRniMxMdHv9csy05u8VpLxgkoyfi9JKs74XV37dLPzfZP+G5/9h169p8l7/ve1CU1e+3vG+GbXa85HS8f6fS/QUmOcmfVeL9EY59IG119v9v6xzjf8Xntszuq6do2PaznN3jsup0DjcwpatM6EnA2tL67OJOcWv+8FEFghHYiSkpI0ZcoU3XDDDRo5cqTef/99lZeXa+3atU3ek5qaqoqKCs9x+PDhIFYMAAA6opB/hqi+Cy+8UFdddZX279/f5BiHwyGHwxHEqgAAQEcX0p8QNXTixAkdOHBA8fHxdpcCAADCSEgHojlz5qioqEj/+te/tHXrVk2aNEmdOnXSvffea3dpAAAgjIT0V2Zff/217r33Xh07dkx9+vTRbbfdpu3bt6tPnz52lwYAAMJISAei1atX210CAAAwQEh/ZQYAABAMBCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMZHYjKMleoLHO5yjJfr9e3xOfY0sxFLZ736OJ5bS2tSV8ubv0O958saf3O9n95fUyr70H4GZP7ot0l+DQ25+0WjlvT4Hyd32uOz3nX63xCzvt+z9USdzq3abJz+3nH3eX8olHfL5xftnn91LxvJEnz8460eS5fVjm/9dmfl+O7H2hvRgciAAAAiUAEAABAIAIAACAQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYjOozTzVbtLaLHPM8fZXQLC2JjcBYGby7nMr/vG5rx1nuur/Jp3XE6uz/7xOX/U+Jz1Gp+z/rxzTMjZ2OL1JjmLGvXd6fyort3a5H2TnZ/pLudO3eX8m+5yfq67nLtavGZbPN3MBq+L8oolSa/llSg9r+S8c72dWxawuuorXHn+ebe+0bK1d71e2tZyvHz9YnFA50P7IBABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMJ5Rgags402VZbxR9zrL73lKMv7QqK8449lGfUcX/5ffa0jS/tcmeJ3/I31CEyMBs43NWdmCMWu9zsflOOva3Lo2r67ND2htE3MKPa8nOTdpknOz1/VJzr96Xt/p/Liu3RaQtX/h/Mpn/z25/5IkPZh7yKt/dt7XXudP5n3T6N7f5x0977pLcs/sFv96XZuVW6o3csv0ph873a9f+60k6b01Z9o/rf7Wc+3DVd/qw1WN59z8dtPrbHujTNuzy/RJ9rkd7T9bce715/V2ut+91HvX+y8zS3zOuf/VM/3/fMV7V/tDCxrvcn/0+ebfv+IX/9n0tZf+0ey9klSy8PPzjvEa//LHrRofCKXpeUFfsyWMCkQAAAC+EIgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYLzOdhcQLN++vlo9I7vZXUZA/N/F4+0uAcB5TMz5s/LvGt7k9UnOIklW3euP6l75Ntm5o26s71FTnLslWZri3KN1k69vdP1u5z6tmXyl7s79p9bceXmj6zPyDitjUqIkaU7e14qQpU4Nxjybd8TT/0LeUUXIUoTO/Ff1K3klnv+6zsgtUYQsLcstlSVpRV3blLXOb/WLyb3ldH6ryZN7e/oL1n2rCVN6+7xnY90Gr2fXLFx5ZjPXTe+caS1JRW+XyXLXvWtu3+/ejqxST//OFaWecQ3tWVKi6/9PrOf8q8UlumZmrP43vURXJcc2Gv+vRcWeuQ6/VCxL0jd/OOrpO/rCEUm1ktyS5ZYl95nXOjOg+MUDnmuqf01S8YIvPedxKdereOFuxT16g0oWfqHYRwd6aihZtFOxs29SyaLPFDv7ZpUs2qHY2beq5OXtiv3Pn6rk5W2eOUte+ajuLu+1JLcsy/tcDWr1dc+5627FJI9TafofFZM8XqXp+YpJnuipsXSxUzEzJ6t08TrFzJyi0sWrFTPzHpUtXqU+M+/Vt6+v8fFPo/3wCREAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMF6HCETp6em67LLL1K1bNw0aNEg7duywuyQAABBGQj4QrVmzRikpKZo/f77+9re/aeDAgRo5cqRKS0vtLg0AAISJkA9ECxYs0PTp0/XAAw/oRz/6kTIzM9W9e3etWLHC7tIAAECYCOnNXU+dOqWdO3cqNTXV0xcREaHhw4dr27ZtPu+prq5WdXW157yiokKSdLzqezXemK7hxnlnj1rPa7dq62aq9Vxzu2u9xp0Zc+bo7nLp+PfVuqBB63K5dPz7U020NWfaqhqvld1W3WurXnWWu97rJvobXFP9uSS5XC5V1q3pT1t/Cz81WsvHO2q5G/V7n5+r72y/y+XS99//4HfbsK7mam70Xvo4r7UaXrPkcrlUffKHFrWnfLQ/WGf+1PxgSacl1dS9lizJfbbSs3+2IiR1qjvqttR0d9K5LSvPbrNpebUul0s1J6sbtFUtbuW25L0tpq/zhm291+7zXK/7Z11z8ns/25Oetul6GrRuSZYl6zy1Wz76Gq55pq1scWtZTb+fVoPzc1V4j7W8xjTuO7PWiSba417tqQZt9cnjOi15NnE9c1j1/oRZ9f4EntvcNaJeBRHuc9e8/zSem8flcujkyeNyubr61Z59RyLckuSua+VpPe9Gw81dvVq3Z39Sr/661y5XN534/ni9NrLJ9vjZtuq4XK7uOl51/NxcnsPteX3mf5ra3LW5zVO9r3d3uXS86oSnjWxRW+lpvedsuNaZc6vBedObu6rxGMutbi6Xjn9/stWtw+Wq+3tbcrvrz9+O3CHsm2++cUtyb9261av/8ccfd996660+75k/f35TKYeDg4ODg4Ojgx0HDhwIRuRwh/xXZq2VmpqqiooKz7Fnzx67SwIAAH7q1atXUNYJ6a/MevfurU6dOqmkpMSrv6SkRHFxcT7vcTgccjgcnvPo6Oh2rREAALSfiIjgfHYT0p8Qde3aVTfddJMKCws9fbW1tSosLNTgwYNtrAwAAISTkP6ESJJSUlI0depU3Xzzzbr11lu1aNEiVVZW6oEHHrC7NAAAECZCPhDdfffdKisr01NPPaXi4mLdeOON2rBhg2JjY1t0f1RUlAYNGqQ9e/aoR48eOn78uHr27Bn01uVyybIsW9amRmqlRmqkRvNq7eg1VlZWavr06V6PwbQny+0O1s+zAQAAhKaQfoYIAAAgGAhEAADAeAQiAABgPAIRAAAwXsj/lFlLpKWlad68eTp9+rTdpQAAAJutXbtWU6ZMadU9YfEJUVFRkScMde4cFhkPAAD4adasWa2+Jyx/7L6srEwxMTF2lwEAAIIkISFBVVVV+ve//y1JOnXqlLp06dLi+8Py45SKigq7SwAAAEF05MgRz+vLLrusVWFICpOvzOqrra3V8OHD7S4DAADY5Nlnn231PWH3ldmMGTOUmZlpdxkAAMAmXbt2VVVVlSzLavE9YfUJ0axZswhDAAAY7tSpU9q6dWur7gmLZ4jcbrdmzJihJUuWePoWLFigrl27auPGjVq/fr2N1QEAgGDo0qWLampqJKnVv4onLL4ymzlzpjIyMjznlmXJsiz16NFDLpfLxsoAAECwde3aVeXl5YqMjGzxPWERiFrzHSEAAAhflmXp888/18CBA1t1X9h8ZQYAAOCvsHqoGgAAwB8EIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAELW0KFDNXv2bLvLAGAAAhEAADAegQgAABiPQASgQ6iurtacOXN08cUX64ILLtCgQYO0efNmz/Xs7GxdeOGF2rhxo6699lr16NFDo0aN0tGjR+0rGkCHQSAC0CHMmjVL27Zt0+rVq7V7925NmTJFo0aN0r59+zxjTp48qRdffFFvvfWWtmzZokOHDmnOnDk2Vg2goyAQAQh5hw4dUlZWltatW6fbb79d/fv315w5c3TbbbcpKyvLM66mpkaZmZm6+eab9ZOf/ESzZs1SYWGhjZUD6Cg6210AAJzP3//+d50+fVpXXXWVV391dbUuuugiz3n37t3Vv39/z3l8fLxKS0uDVieAjotABCDknThxQp06ddLOnTvVqVMnr2s9evTwvO7SpYvXNcuy5Ha7g1IjgI6NQAQg5P34xz/W6dOnVVpaqttvv93ucgCEIZ4hAhDyrrrqKt133326//77lZubq4MHD2rHjh1KS0vTe++9Z3d5AMIAgQhAh5CVlaX7779fjz32mK6++mpNnDhRn376qS655BK7SwMQBiw3X7ADAADD8QkRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIz3/wGXh8Kq79ajWAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# count plot on single categorical variable\n",
    "sns.countplot(x ='len', data = df)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e9a98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropping rows having context len less than 20\n",
    "\n",
    "df = df.drop(df[df['len'] < 20].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3977ca55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10578.000000\n",
       "mean       629.003781\n",
       "std        441.932427\n",
       "min         21.000000\n",
       "25%        368.250000\n",
       "50%        551.000000\n",
       "75%        771.000000\n",
       "max       7493.000000\n",
       "Name: len, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df35d60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>source</th>\n",
       "      <th>context</th>\n",
       "      <th>context_summary</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>extracting the top-k value-indices from a 1-d ...</td>\n",
       "      <td>as of pull request #496 torch now includes a b...</td>\n",
       "      <td>https://stackoverflow.com/questions/34750268/</td>\n",
       "      <td>Answer: as of pull request #496 torch now incl...</td>\n",
       "      <td>To extract the top-k value-indices from a 1-d ...</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>how to display custom images in tensorboard (e...</td>\n",
       "      <td>it is quite easy to do if you have the image i...</td>\n",
       "      <td>https://stackoverflow.com/questions/38543850/</td>\n",
       "      <td>Answer: it is quite easy to do if you have the...</td>\n",
       "      <td>Answer: use the gen_plot() function to create ...</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>python wheels: cp27mu not supported</td>\n",
       "      <td>this is exactly that. \\nrecompile python under...</td>\n",
       "      <td>https://stackoverflow.com/questions/41767005/</td>\n",
       "      <td>Answer: this is exactly that. \\nrecompile pyth...</td>\n",
       "      <td>Answer: To fix the issue of the \"cp27mu not su...</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>loading torch7 trained models (.t7) in pytorch</td>\n",
       "      <td>as of pytorch 1.0 torch.utils.serialization is...</td>\n",
       "      <td>https://stackoverflow.com/questions/41861354/</td>\n",
       "      <td>Answer: as of pytorch 1.0 torch.utils.serializ...</td>\n",
       "      <td>Question: loading torch7 trained models (.t7) ...</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pytorch: how to use dataloaders for custom dat...</td>\n",
       "      <td>yes, that is possible. just create the objects...</td>\n",
       "      <td>https://stackoverflow.com/questions/41924453/</td>\n",
       "      <td>Answer: yes, that is possible. just create the...</td>\n",
       "      <td>Question: How to use dataloaders for custom da...</td>\n",
       "      <td>1171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10573</th>\n",
       "      <td>10758</td>\n",
       "      <td>is it possible to perform quantization on dens...</td>\n",
       "      <td>here's how to do this on densenet169 from torc...</td>\n",
       "      <td>https://stackoverflow.com/questions/74612146/</td>\n",
       "      <td>Answer: here's how to do this on densenet169 f...</td>\n",
       "      <td>Answer: To perform quantization on densenet169...</td>\n",
       "      <td>1612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10574</th>\n",
       "      <td>10759</td>\n",
       "      <td>why when the batch size increased, the epoch t...</td>\n",
       "      <td>as you already noticed, there are many factors...</td>\n",
       "      <td>https://stackoverflow.com/questions/74637151/</td>\n",
       "      <td>Answer: as you already noticed, there are many...</td>\n",
       "      <td>Q: Why does increasing the batch size increase...</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10575</th>\n",
       "      <td>10760</td>\n",
       "      <td>why does stablediffusionpipeline return black ...</td>\n",
       "      <td>apparently it is indeed an apple silicon (m1/m...</td>\n",
       "      <td>https://stackoverflow.com/questions/74642594/</td>\n",
       "      <td>Answer: apparently it is indeed an apple silic...</td>\n",
       "      <td>Answer: The stablediffusionpipeline returns bl...</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10576</th>\n",
       "      <td>10761</td>\n",
       "      <td>locating tags in a string in php (with respect...</td>\n",
       "      <td>i think i've got something. how about this:\\nf...</td>\n",
       "      <td>https://stackoverflow.com/questions/74671399/</td>\n",
       "      <td>Answer: i think i've got something. how about ...</td>\n",
       "      <td>Answer: You can use the function label_italics...</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10577</th>\n",
       "      <td>10762</td>\n",
       "      <td>bgr to rgb for cub_200 images by image.split()</td>\n",
       "      <td>i would strongly recommend you use skimage.io ...</td>\n",
       "      <td>https://stackoverflow.com/questions/74679922/</td>\n",
       "      <td>Answer: i would strongly recommend you use ski...</td>\n",
       "      <td>Answer: To convert bgr to rgb for cub_200 imag...</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10578 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                           question  \\\n",
       "0          0  extracting the top-k value-indices from a 1-d ...   \n",
       "1          1  how to display custom images in tensorboard (e...   \n",
       "2          2                python wheels: cp27mu not supported   \n",
       "3          3     loading torch7 trained models (.t7) in pytorch   \n",
       "4          4  pytorch: how to use dataloaders for custom dat...   \n",
       "...      ...                                                ...   \n",
       "10573  10758  is it possible to perform quantization on dens...   \n",
       "10574  10759  why when the batch size increased, the epoch t...   \n",
       "10575  10760  why does stablediffusionpipeline return black ...   \n",
       "10576  10761  locating tags in a string in php (with respect...   \n",
       "10577  10762     bgr to rgb for cub_200 images by image.split()   \n",
       "\n",
       "                                                  answer  \\\n",
       "0      as of pull request #496 torch now includes a b...   \n",
       "1      it is quite easy to do if you have the image i...   \n",
       "2      this is exactly that. \\nrecompile python under...   \n",
       "3      as of pytorch 1.0 torch.utils.serialization is...   \n",
       "4      yes, that is possible. just create the objects...   \n",
       "...                                                  ...   \n",
       "10573  here's how to do this on densenet169 from torc...   \n",
       "10574  as you already noticed, there are many factors...   \n",
       "10575  apparently it is indeed an apple silicon (m1/m...   \n",
       "10576  i think i've got something. how about this:\\nf...   \n",
       "10577  i would strongly recommend you use skimage.io ...   \n",
       "\n",
       "                                              source  \\\n",
       "0      https://stackoverflow.com/questions/34750268/   \n",
       "1      https://stackoverflow.com/questions/38543850/   \n",
       "2      https://stackoverflow.com/questions/41767005/   \n",
       "3      https://stackoverflow.com/questions/41861354/   \n",
       "4      https://stackoverflow.com/questions/41924453/   \n",
       "...                                              ...   \n",
       "10573  https://stackoverflow.com/questions/74612146/   \n",
       "10574  https://stackoverflow.com/questions/74637151/   \n",
       "10575  https://stackoverflow.com/questions/74642594/   \n",
       "10576  https://stackoverflow.com/questions/74671399/   \n",
       "10577  https://stackoverflow.com/questions/74679922/   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Answer: as of pull request #496 torch now incl...   \n",
       "1      Answer: it is quite easy to do if you have the...   \n",
       "2      Answer: this is exactly that. \\nrecompile pyth...   \n",
       "3      Answer: as of pytorch 1.0 torch.utils.serializ...   \n",
       "4      Answer: yes, that is possible. just create the...   \n",
       "...                                                  ...   \n",
       "10573  Answer: here's how to do this on densenet169 f...   \n",
       "10574  Answer: as you already noticed, there are many...   \n",
       "10575  Answer: apparently it is indeed an apple silic...   \n",
       "10576  Answer: i think i've got something. how about ...   \n",
       "10577  Answer: i would strongly recommend you use ski...   \n",
       "\n",
       "                                         context_summary   len  \n",
       "0      To extract the top-k value-indices from a 1-d ...   557  \n",
       "1      Answer: use the gen_plot() function to create ...   994  \n",
       "2      Answer: To fix the issue of the \"cp27mu not su...   671  \n",
       "3      Question: loading torch7 trained models (.t7) ...   696  \n",
       "4      Question: How to use dataloaders for custom da...  1171  \n",
       "...                                                  ...   ...  \n",
       "10573  Answer: To perform quantization on densenet169...  1612  \n",
       "10574  Q: Why does increasing the batch size increase...   913  \n",
       "10575  Answer: The stablediffusionpipeline returns bl...   621  \n",
       "10576  Answer: You can use the function label_italics...   526  \n",
       "10577  Answer: To convert bgr to rgb for cub_200 imag...   463  \n",
       "\n",
       "[10578 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27983ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('so_context_with_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5920f91",
   "metadata": {},
   "source": [
    "## create faiss index to use this during query time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b6b6b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunking pages into smaller sub-pages\n",
      "0 pages done\n",
      "500 pages done\n",
      "1000 pages done\n",
      "1500 pages done\n",
      "2000 pages done\n",
      "2500 pages done\n",
      "3000 pages done\n",
      "3500 pages done\n",
      "4000 pages done\n",
      "4500 pages done\n",
      "5000 pages done\n",
      "5500 pages done\n",
      "6000 pages done\n",
      "6500 pages done\n",
      "7000 pages done\n",
      "7500 pages done\n",
      "8000 pages done\n",
      "8500 pages done\n",
      "9000 pages done\n",
      "9500 pages done\n",
      "10000 pages done\n",
      "10500 pages done\n",
      "10744 pages done\n"
     ]
    }
   ],
   "source": [
    "def split_pages(df):\n",
    "    splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=2048)\n",
    "    print('chunking pages into smaller sub-pages')\n",
    "            \n",
    "    pages = []\n",
    "\n",
    "    for index, i in df.iterrows():\n",
    "        texts = \"context: \" + i['context_summary']\n",
    "        meta = {'source':i['source']}\n",
    "        pages.extend(splitter.create_documents([texts], [meta]))\n",
    "    pickle.dump(pages, open('so_context_summary_pages.pkl', 'wb'))\n",
    "\n",
    "split_pages(df)\n",
    "\n",
    "\n",
    "\n",
    "pages = pickle.load(open('so_context_summary_pages.pkl', 'rb'))\n",
    "\n",
    "docsearch = FAISS.from_documents([pages.pop(0)], embeddings)\n",
    "i, step = 0, 50\n",
    "while i<len(pages):\n",
    "    if i%500==0:\n",
    "        print(i,'pages done')\n",
    "    texts = [d.page_content for d in pages[i:i+step]]\n",
    "    meta = [d.metadata for d in pages[i:i+step]]\n",
    "    docsearch.add_texts(texts, meta)\n",
    "    i += step\n",
    "print(len(pages),'pages done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5163789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch.save_local('so_context_summary_faiss_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7759eeb",
   "metadata": {},
   "source": [
    "## preparing alpaca lora dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "496d00c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    d = { \"instruction\": row['question'][0:1024],\n",
    "          \"input\": row['context_summary'][0:1024],\n",
    "          \"output\": row['answer'][0:2048]\n",
    "        }\n",
    "    \n",
    "    data.append(d)\n",
    "    \n",
    "\n",
    "with open('so_context_with_summary.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5781a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
