{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch-Assistant\n",
    "\n",
    "Given a query, we:\n",
    "\n",
    "a) find `k` context documents most likely to contain the answer (k-nearest-neighbors)\n",
    "\n",
    "b) engineer a prompt with these `k` documents along with 2 generic examples of Q&A (see [ref](https://github.com/hwchase17/langchain/blob/0b204d8c2134cc488c333e86e0440977bdacf216/langchain/chains/qa_with_sources/stuff_prompt.py#L4))\n",
    "\n",
    "c) hope GPT infers the right answer from the given context\n",
    "\n",
    "d) verify GPT's answer by cross-checking the cited context document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `langchain`, an OSS library that has helper functions for the steps above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import llms \n",
    "# dir(llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import yaml\n",
    "import time\n",
    "import pickle\n",
    "import tempfile\n",
    "import subprocess\n",
    "import pathlib\n",
    "from bs4 import BeautifulSoup as BSHTML\n",
    "from requests.models import JSONDecodeError\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.llms import OpenAI, GPT4All\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BYO API Key\n",
    "\n",
    "Get one here https://beta.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBED = \"openai\"\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "EMBED = \"hg\"\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking\n",
    "Each page is chunked into smaller sub-pages. This is a workaround for LLM prompt size limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"knowledgebase\"\n",
    "vector_folder = f\"vectorstore/{EMBED.lower()}_embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_pickle(page_iter, src_name):\n",
    "    docs = []\n",
    "    splitter = MarkdownTextSplitter(chunk_size=1024, chunk_overlap=0)\n",
    "    for page in page_iter:\n",
    "        docs.extend((splitter.create_documents([page['text']], [page['metadata']])))\n",
    "    pickle.dump(docs, open(f'{base_folder}/{src_name}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blogs(repo_owner='pytorch', repo_name='pytorch.github.io'):\n",
    "    with tempfile.TemporaryDirectory() as d:\n",
    "#         subprocess.check_call(\n",
    "#             f\"git clone --depth 1 https://github.com/{repo_owner}/{repo_name}.git .\",\n",
    "#             cwd=d,\n",
    "#             shell=True,\n",
    "#         )\n",
    "#         git_sha = (\n",
    "#             subprocess.check_output(\"git rev-parse HEAD\", shell=True, cwd=d)\n",
    "#             .decode(\"utf-8\")\n",
    "#             .strip()\n",
    "#         )\n",
    "        repo_path = pathlib.Path(\"/home/ubuntu/Repositories/fb/langchain/pytorch.github.io\")\n",
    "        markdown_files = list(repo_path.glob(\"_posts/*.md\"))\n",
    "        for markdown_file in markdown_files:\n",
    "            with open(markdown_file, \"r\") as f:\n",
    "                filename = markdown_file.parts[-1]\n",
    "                title = os.path.splitext('-'.join(filename.split('-')[3:]))[0]\n",
    "                blog_url = f\"https://pytorch.org/blog/{title}/\"\n",
    "                yield {'text': f.read(), 'metadata': {\"source\": blog_url}}\n",
    "\n",
    "# if you're in a hurry\n",
    "# !curl \"https://pytorch-qabot.s3.amazonaws.com/knowledgebase/blogs.pkl\" --create-dirs -O --output-dir ./knowledgebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_and_pickle(get_blogs(), 'blogs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_forum(period='weekly'):\n",
    "#     host = \"https://discuss.pytorch.org\"\n",
    "\n",
    "#     def _get_accepted_topics(period, page=0, dst=[]):\n",
    "#         resp = requests.get(host+f'/top.json?page={page}&period={period}&per_page=100').json()\n",
    "#         dst.extend([(d['id'], d['title']) for d in resp['topic_list']['topics'] if d['has_accepted_answer'] is True])\n",
    "#         if 'more_topics_url' in resp['topic_list'].keys():\n",
    "#             page += 1\n",
    "#             _get_accepted_topics(period=period, page=page, dst=dst)\n",
    "#         return dst\n",
    "\n",
    "#     def _process_cooked(cooked):\n",
    "#         bs = BSHTML(cooked)\n",
    "#         p = ' '.join([x.get_text() for x in bs.find_all('p')])\n",
    "#         return p\n",
    "\n",
    "#     solved_topics = _get_accepted_topics(period)\n",
    "#     for t, title in solved_topics:\n",
    "#         try:\n",
    "#             r = requests.get(host+f'/t/{t}/posts.json').json()\n",
    "#         except JSONDecodeError:\n",
    "#             continue\n",
    "#         try:\n",
    "#             q = title + '? ' + _process_cooked(r['post_stream']['posts'][0]['cooked'])\n",
    "#             a = _process_cooked([x['cooked'] for x in r['post_stream']['posts'] if x['accepted_answer'] is True][0])\n",
    "#         except IndexError:\n",
    "#             print(f\"Skipping https://discuss.pytorch.org/t/{t}/\")\n",
    "#             continue\n",
    "#         text = \"QUESTION: \" + q + ' ANSWER: ' + a\n",
    "#         yield {'text': text, 'metadata': {'source': f\"https://discuss.pytorch.org/t/{t}/\"}}\n",
    "\n",
    "# preprocess_and_pickle(get_forum(), 'forum')\n",
    "\n",
    "# # if you're in a hurry\n",
    "# # !curl \"https://pytorch-qabot.s3.amazonaws.com/knowledgebase/forum.pkl\" --create-dirs -O --output-dir ./knowledgebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch/docs/stable/*.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_docs(repo_owner='pytorch', repo_name='pytorch'):\n",
    "#     with tempfile.TemporaryDirectory() as d:\n",
    "#         subprocess.check_call(\n",
    "#             f\"git clone --depth 1 https://github.com/{repo_owner}/{repo_name}.git .\",\n",
    "#             cwd=d,\n",
    "#             shell=True,\n",
    "#         )\n",
    "#         repo_path = pathlib.Path(d + '/docs/source')\n",
    "#         # repo_path = pathlib.Path('pytorch/docs/source')\n",
    "#         markdown_files = list(repo_path.glob(\"**/*.rst\"))\n",
    "#         for markdown_file in markdown_files:\n",
    "#             relative_path = markdown_file.relative_to(repo_path)\n",
    "#             if '_' in markdown_file.name:\n",
    "#                 continue\n",
    "#             with open(markdown_file, \"r\") as f:\n",
    "#                 i = markdown_file.parts.index('source')\n",
    "#                 filename = os.path.splitext(relative_path)[0]\n",
    "#                 page_url = f\"https://pytorch.org/docs/stable/{filename}.html\"\n",
    "#                 yield {'text': f.read(), 'metadata': {\"source\": page_url}, \"file\":relative_path}\n",
    "\n",
    "# preprocess_and_pickle(get_docs(), 'docs')\n",
    "\n",
    "\n",
    "# # if you're in a hurry\n",
    "# # !curl \"https://pytorch-qabot.s3.amazonaws.com/knowledgebase/docs.pkl\" --create-dirs -O --output-dir ./knowledgebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.error import RateLimitError\n",
    "\n",
    "def create_vectorstores():\n",
    "    pathlib.Path(vector_folder).mkdir(parents=True, exist_ok=True)\n",
    "    for pages_path in os.listdir(base_folder):\n",
    "        source = os.path.splitext(pages_path)[0]\n",
    "        out_path = f\"vectorstore/{EMBED.lower()}_embeddings/{source}.pkl\"\n",
    "        if os.path.exists(out_path):\n",
    "            continue\n",
    "            \n",
    "        pages = pickle.load(open(os.path.join(base_folder, pages_path), 'rb'))\n",
    "        docsearch = FAISS.from_documents([pages.pop(0)], embeddings)\n",
    "        i, step = 0, 30\n",
    "        while i<len(pages):\n",
    "            texts = [d.page_content for d in pages[i:i+step]]\n",
    "            meta = [d.metadata for d in pages[i:i+step]]\n",
    "            try:\n",
    "                docsearch.add_texts(texts, meta)\n",
    "                i += step\n",
    "            except Exception as err:\n",
    "                print(\"Hit RateLimit @ i=\", i, err)\n",
    "                time.sleep(60)\n",
    "        pickle.dump(docsearch, open(out_path, \"wb\"))\n",
    "\n",
    "create_vectorstores()\n",
    "\n",
    "# if you're in a hurry and on an arm64 \n",
    "# !curl \"https://pytorch-qabot.s3.amazonaws.com/vectorstore/openai_embeddings/blogs.pkl\" --create-dirs -O --output-dir ./vectorstore/openai_embeddings\n",
    "# !curl \"https://pytorch-qabot.s3.amazonaws.com/vectorstore/openai_embeddings/docs.pkl\" --create-dirs -O --output-dir ./vectorstore/openai_embeddings\n",
    "# !curl \"https://pytorch-qabot.s3.amazonaws.com/vectorstore/openai_embeddings/forum.pkl\" --create-dirs -O --output-dir ./vectorstore/openai_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyllamacpp in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (1.0.6)\n",
      "Requirement already satisfied: streamlit in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from pyllamacpp) (1.21.0)\n",
      "Requirement already satisfied: streamlit-ace in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from pyllamacpp) (0.1.1)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from pyllamacpp) (0.1.98)\n",
      "Requirement already satisfied: torch in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from pyllamacpp) (2.0.0)\n",
      "Requirement already satisfied: altair<5,>=3.2.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (4.2.2)\n",
      "Requirement already satisfied: blinker>=1.0.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (1.6.2)\n",
      "Requirement already satisfied: cachetools>=4.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (5.3.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (6.4.1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (1.24.2)\n",
      "Requirement already satisfied: packaging>=14.1 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (23.1)\n",
      "Requirement already satisfied: pandas<2,>=0.25 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (1.5.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (9.5.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.12 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=4.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (11.0.0)\n",
      "Requirement already satisfied: pympler>=0.9 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.4 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (2.28.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (13.3.4)\n",
      "Requirement already satisfied: toml in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (4.5.0)\n",
      "Requirement already satisfied: tzlocal>=1.1 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (4.3)\n",
      "Requirement already satisfied: validators>=0.2 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (0.20.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (3.1.31)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (0.8.1b0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (6.3)\n",
      "Requirement already satisfied: watchdog in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from streamlit->pyllamacpp) (3.0.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (3.11.0)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from torch->pyllamacpp) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->pyllamacpp) (67.6.0)\n",
      "Requirement already satisfied: wheel in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->pyllamacpp) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from triton==2.0.0->torch->pyllamacpp) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from triton==2.0.0->torch->pyllamacpp) (16.0.1)\n",
      "Requirement already satisfied: entrypoints in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from altair<5,>=3.2.0->streamlit->pyllamacpp) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from altair<5,>=3.2.0->streamlit->pyllamacpp) (4.17.3)\n",
      "Requirement already satisfied: toolz in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from altair<5,>=3.2.0->streamlit->pyllamacpp) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from gitpython!=3.1.19->streamlit->pyllamacpp) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from importlib-metadata>=1.4->streamlit->pyllamacpp) (3.15.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from pandas<2,>=0.25->streamlit->pyllamacpp) (2023.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from jinja2->torch->pyllamacpp) (2.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from python-dateutil->streamlit->pyllamacpp) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from requests>=2.4->streamlit->pyllamacpp) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from requests>=2.4->streamlit->pyllamacpp) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from requests>=2.4->streamlit->pyllamacpp) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from requests>=2.4->streamlit->pyllamacpp) (2022.12.7)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from rich>=10.11.0->streamlit->pyllamacpp) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from rich>=10.11.0->streamlit->pyllamacpp) (2.15.0)\n",
      "Requirement already satisfied: pytz-deprecation-shim in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from tzlocal>=1.1->streamlit->pyllamacpp) (0.1.0.post0)\n",
      "Requirement already satisfied: backports.zoneinfo in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from tzlocal>=1.1->streamlit->pyllamacpp) (0.2.1)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from validators>=0.2->streamlit->pyllamacpp) (5.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from sympy->torch->pyllamacpp) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit->pyllamacpp) (5.0.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit->pyllamacpp) (23.1.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit->pyllamacpp) (5.12.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit->pyllamacpp) (1.3.10)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit->pyllamacpp) (0.19.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit->pyllamacpp) (0.1.2)\n",
      "Requirement already satisfied: tzdata in /home/ubuntu/.virtualenvs/langchain/lib/python3.8/site-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit->pyllamacpp) (2023.3)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install pyllamacpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyllamacpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# qa_chain formats the prompt with context docs, passes it to the LLM and returns the answer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# base_llm = OpenAI(temperature=0.2)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m base_llm \u001b[38;5;241m=\u001b[39m \u001b[43mGPT4All\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m qa_chain \u001b[38;5;241m=\u001b[39m load_qa_with_sources_chain(base_llm, chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/langchain/lib/python3.8/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/langchain/lib/python3.8/site-packages/pydantic/main.py:1102\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/langchain/lib/python3.8/site-packages/langchain/llms/gpt4all.py:133\u001b[0m, in \u001b[0;36mGPT4All.validate_environment\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    130\u001b[0m     llama_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_llama_param_names()\n\u001b[1;32m    131\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m values\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m llama_keys}\n\u001b[1;32m    132\u001b[0m     values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m GPT4AllModel(\n\u001b[0;32m--> 133\u001b[0m         ggml_model\u001b[38;5;241m=\u001b[39m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m    135\u001b[0m     )\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import pyllamacpp python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install pyllamacpp`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model'"
     ]
    }
   ],
   "source": [
    "# qa_chain formats the prompt with context docs, passes it to the LLM and returns the answer\n",
    "\n",
    "# base_llm = OpenAI(temperature=0.2)\n",
    "base_llm = GPT4All()\n",
    "qa_chain = load_qa_with_sources_chain(base_llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY:  How to properly save embeddings?\n",
      "From  blogs\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'qa_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m     relevant_docs \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39msimilarity_search(query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;124m\"\u001b[39m, source)\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mqa_chain\u001b[49m\u001b[38;5;241m.\u001b[39mrun(input_documents\u001b[38;5;241m=\u001b[39mrelevant_docs, question\u001b[38;5;241m=\u001b[39mquery))\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m============\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qa_chain' is not defined"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"How to properly save embeddings?\",\n",
    "    \"How to correctly access attribute of a custom layer inherited nn.Sequential class?\",\n",
    "    \"How to assign a tensor to another tensor at different rows and columns?\",\n",
    "    \"How to Recursively transforming Pytorch code to JIT script?\",\n",
    "    \"Is current pytorch 2.0 version stable?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(\"QUERY: \", query)\n",
    "    for vectordb in os.listdir('vectorstore/openai_embeddings'):\n",
    "        source = os.path.splitext(vectordb)[0]\n",
    "        vectordb = f'vectorstore/{EMBED}_embeddings/{vectordb}'\n",
    "        db = pickle.load(open(vectordb, 'rb'))\n",
    "        relevant_docs = db.similarity_search(query, k=4)\n",
    "        print(\"From \", source)\n",
    "        print(qa_chain.run(input_documents=relevant_docs, question=query))\n",
    "        print(\"------\")\n",
    "    print(\"\\n============\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "0862dbbfc0b6f47d31518a473bd1d9b6fc9c85b24ab0e62a07ab361177f3e201"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
